{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Source : https://medium.com/@dilip.voleti/classification-using-word2vec-b1d79d375381\n",
        "# Data : https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset"
      ],
      "metadata": {
        "id": "k9XSeUOprbtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install gensim==4.2.0"
      ],
      "metadata": {
        "id": "tktipx_9tKAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlFz-sa1rJfT"
      },
      "outputs": [],
      "source": [
        "# Read in the data and clean up column names\n",
        "import gensim\n",
        "print(gensim.__version__)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', 100)\n",
        "messages = pd.read_csv('SelfShiksha_ANN_MCQ89_Word2Vec.csv', encoding='latin-1')"
      ],
      "metadata": {
        "id": "WzSFJMoEranP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "id": "Nj0B_6S-rpu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = messages.drop(labels = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis = 1)\n",
        "messages.columns = [\"label\", \"text\"]\n",
        "messages.head()"
      ],
      "metadata": {
        "id": "KLzp-kmxrm_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean data using the built in cleaner in gensim\n",
        "messages['text_clean'] = messages['text'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
        "messages.head()"
      ],
      "metadata": {
        "id": "zl4FtFJLrnap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding the label column\n",
        "messages['label']=messages['label'].map({'ham':1,'spam':0})"
      ],
      "metadata": {
        "id": "k8Dv94XCrxGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split (messages['text_clean'], messages['label'] , test_size=0.2)"
      ],
      "metadata": {
        "id": "X5DILTSYr1IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the word2vec model\n",
        "\n",
        "# vector_size - size of the vectors we want\n",
        "\n",
        "# window - number words before and after the focus word that itâ€™ll consider as context for the word\n",
        "\n",
        "# min_count - the number of times a word must appear in our corpus in order to create a word vector.\n",
        "\n",
        "w2v_model = gensim.models.Word2Vec(X_train, vector_size = 100, window = 5, min_count = 2)\n",
        "\n",
        "# This line trains the Word2Vec model using our X_train dataset.\n",
        "# You can also use pre-trained Word2Vec vectors and compare how these perform \n",
        "# as compared to the above model : https://www.kaggle.com/datasets/leadbest/googlenewsvectorsnegative300"
      ],
      "metadata": {
        "id": "ExBUWvJBr12J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the most similar words to \"king\" based on word vectors from our trained model\n",
        "w2v_model.wv.most_similar('king')"
      ],
      "metadata": {
        "id": "jbnKKUeMr7b1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.similarity('life', 'death')"
      ],
      "metadata": {
        "id": "w2PxGVO9tj-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.similarity('hello', 'bye')"
      ],
      "metadata": {
        "id": "YDw1yo-NtoKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.similarity('hello', 'canada')"
      ],
      "metadata": {
        "id": "33UypQzJuBec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.similarity('cup', 'canada')"
      ],
      "metadata": {
        "id": "4MJxYtytuce4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This creates the embedding vector for each sentence in the dataset.\n",
        "\n",
        "words = set(w2v_model.wv.index_to_key )\n",
        "X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
        "                         for ls in X_train])\n",
        "X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
        "                         for ls in X_test])"
      ],
      "metadata": {
        "id": "lbt4eJU1s3yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Why is the length of the sentence different than the length of the sentence vector?\n",
        "for i, v in enumerate(X_train_vect):\n",
        "    print(len(X_train.iloc[i]), len(v))"
      ],
      "metadata": {
        "id": "VINhKGpJtALm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute sentence vectors by averaging the word vectors for the words contained in the sentence\n",
        "X_train_vect_avg = []\n",
        "for v in X_train_vect:\n",
        "    if v.size:\n",
        "        X_train_vect_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        X_train_vect_avg.append(np.zeros(100, dtype=float))\n",
        "        \n",
        "X_test_vect_avg = []\n",
        "for v in X_test_vect:\n",
        "    if v.size:\n",
        "        X_test_vect_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        X_test_vect_avg.append(np.zeros(100, dtype=float))"
      ],
      "metadata": {
        "id": "mKBcr-shvhbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Are our sentence vector lengths consistent?\n",
        "for i, v in enumerate(X_train_vect_avg):\n",
        "    print(len(X_train.iloc[i]), len(v))"
      ],
      "metadata": {
        "id": "w4EIUKT7xBJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate and fit a basic Random Forest model on top of the vectors\n",
        "# Write your own code to use Logistic Regression and ANN to do this classification.\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "rf_model = rf.fit(X_train_vect_avg, y_train.values.ravel())"
      ],
      "metadata": {
        "id": "LbjXJNa_xEDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the trained model to make predictions on the test data\n",
        "y_pred = rf_model.predict(X_test_vect_avg)\n"
      ],
      "metadata": {
        "id": "MDtW-1rHxIKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
        "    round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))"
      ],
      "metadata": {
        "id": "7KIpWAmZxK-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VFlMhYkDxOGi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}