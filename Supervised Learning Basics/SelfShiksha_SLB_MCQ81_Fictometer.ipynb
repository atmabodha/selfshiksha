{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Application of Logistic Regression for \n",
        "## classifying English articles into fiction and non-fiction category"
      ],
      "metadata": {
        "id": "x2LVh2Mab7CB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For more details : https://medium.com/@atmabodha/fictometer-a-simple-and-explainable-algorithm-for-sentiment-analysis-31186d2a8c7e"
      ],
      "metadata": {
        "id": "vbq-ye7xcDFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK is a popular library used for analysing texts\n",
        "# The brown corpus dataset is present inside this library\n",
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "nltk.download('brown')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "LhWIWKXdb5i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Details of all the information contained in the NLTK brown corpus\n",
        "help(brown)"
      ],
      "metadata": {
        "id": "2TtbTHX4dWNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of all text categories present in the brown corpus\n",
        "brown.categories()"
      ],
      "metadata": {
        "id": "ulutL92eeC9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of all articles within the 'news' category\n",
        "brown.fileids('news')"
      ],
      "metadata": {
        "id": "NLWEJF3DeJWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of the first 20 tagged words in article number 'ca44'\n",
        "# As you can see, each article is divided into individual words (tokenization), \n",
        "# and for each word, the corresponging Part of Speech (POS) tag is specified.\n",
        "# You can use the functions defined later on to convert these POS tags to universal tags that are easy to understand.\n",
        "\n",
        "print(type(brown.tagged_words('ca44')))\n",
        "print(len(brown.tagged_words('ca44')))\n",
        "print(brown.tagged_words('ca44')[0:20])"
      ],
      "metadata": {
        "id": "Pya0pMSOeZuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Fictometer algorithm is based on the Part of Speech (POS) tags in a text. For a given input text, it first counts the number adverbs, adjectives, and pronounds in the text and uses it as an input to the Logistic Regression algorithm to do the classification.\n",
        "\n",
        "We will be using the Brown corpus dataset for this work, and this corpus has both the text as well as the POS tags (added by human experts). However, the POS tags present in this corpus are finer, meaning adjectives can be further sub-divided into finer categories. But for our analysis, we only need the high level tags. And so the first step is to convert/group the finer tags into high level tags, which we do through the functions defined below."
      ],
      "metadata": {
        "id": "GAjAUnURa3ZG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfrClRr4Xqm3"
      },
      "outputs": [],
      "source": [
        "# Define functions to count the number of POS tags in the text.\n",
        "\n",
        "# This function counts the number of adjectives\n",
        "def n_adj(text):\n",
        "    adj=0\n",
        "    for i in text:\n",
        "        if i[0] == 'J':\n",
        "            adj=adj+1\n",
        "    return adj\n",
        "\n",
        "# This function counts the number of nouns\n",
        "def n_noun(text):\n",
        "    noun=0\n",
        "    for i in text:\n",
        "        if ((i[0] == 'N') and (i[1] != 'C')):\n",
        "            noun=noun+1\n",
        "    return noun\n",
        "\n",
        "# This function counts the number of verbs\n",
        "def n_verb(text):\n",
        "    verb=0\n",
        "    for i in text:\n",
        "        if i[0] == 'V':\n",
        "            verb=verb+1\n",
        "    return verb\n",
        "\n",
        "# This function counts the number of pronouns\n",
        "def n_pronoun(text):\n",
        "    pronoun=0\n",
        "    for i in text:\n",
        "        if (i[0] == 'P') or (i[:3] in ['WP$','WPO','WPS']):\n",
        "            pronoun=pronoun+1\n",
        "    return pronoun\n",
        "\n",
        "# This function counts the number of adverbs\n",
        "def n_adv(text):\n",
        "    adv=0\n",
        "    for i in text:\n",
        "        if (i[0] == 'R') or (i[:3] in ['WRB']):\n",
        "            adv=adv+1\n",
        "    return adv\n",
        "\n",
        "# This function outputs the universal high level tag using a finer tag as input\n",
        "def func_utag(tag):\n",
        "    if tag[0] == 'J' or tag == 'ADJ':\n",
        "        utag='ADJ'\n",
        "    elif ((tag[0] == 'N') and (tag[1] != 'C')) or tag == 'NOUN':\n",
        "        utag='NOUN'\n",
        "    elif tag[0] == 'V' or tag == 'VERB':\n",
        "        utag='VERB'\n",
        "    elif (tag[0] == 'P') or (tag[:3] in ['WP$','WPO','WPS']) or tag == 'PRON':\n",
        "        utag='PRON'\n",
        "    elif (tag[0] == 'R') or (tag[:3] in ['WRB']) or tag == 'ADV':\n",
        "        utag='ADV'\n",
        "    else:\n",
        "        utag='unknown'\n",
        "    return utag\n",
        "\n",
        "# This function outputs True or False depending on whether the input tag is one of the 5 high level universal tags or not.\n",
        "def func_is5tag(tag):\n",
        "    if tag in ['ADJ','ADV','NOUN','PRON','VERB']:\n",
        "        is5tag=True\n",
        "    else:\n",
        "        is5tag=False\n",
        "    return is5tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xcch9aViXqm4"
      },
      "outputs": [],
      "source": [
        "# This creates an empty dataframe with the defined columns\n",
        "brownpostable=pd.DataFrame(columns=['category','filename','ADJ','ADV','NOUN','VERB','PRON','RADJPRON','RADVADJ'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro0XGpj-Xqm5"
      },
      "outputs": [],
      "source": [
        "# Take each article from the Brown corpus, count the number of each universal POS tag in the article, \n",
        "# and populate the DataFrame\n",
        "\n",
        "for i in brown.categories():\n",
        "  # This loop iterates over all the 15 categories of articles present in the Brown corpus\n",
        "  \n",
        "    for j in brown.fileids(categories=i):\n",
        "      # This loop iterates over all the articles present in the chosen category\n",
        "\n",
        "        taggedwords=brown.tagged_words(j)\n",
        "        taglist=[]\n",
        "        for k in taggedwords:\n",
        "          # This loop iterates over all the tagged words in the chosen article\n",
        "\n",
        "            taglist.append(k[1])\n",
        "        adj=n_adj(taglist) # Count the number of adjectives in the article\n",
        "        adv=n_adv(taglist) # Count the number of adverbs in the article\n",
        "        noun=n_noun(taglist) # Count the number of nouns in the article\n",
        "        verb=n_verb(taglist) # Count the number of verbs in the article\n",
        "        pronoun=n_pronoun(taglist) # Count the number of pronouns in the article\n",
        "\n",
        "        # Append the above information for each article to the DataFrame\n",
        "        brownpostable=brownpostable.append({'category' : i,'filename' : j, 'ADJ' : int(adj), 'ADV' : int(adv), 'NOUN' : int(noun), 'VERB' : int(verb), 'PRON' : int(pronoun)},ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6b3qD7MXqm5"
      },
      "outputs": [],
      "source": [
        "brownpostable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNIvYkTvXqm5"
      },
      "outputs": [],
      "source": [
        "# Compute the ratio of Adjectives to Pronouns, and the ratio of Adverbs to Adjectives in each article \n",
        "# and populate the last 2 columns of the DataFrame\n",
        "\n",
        "for i in range(len(brownpostable)):\n",
        "    adj=brownpostable.ADJ.iloc[i]\n",
        "    adv=brownpostable.ADV.iloc[i]\n",
        "    pronoun=brownpostable.PRON.iloc[i]\n",
        "    brownpostable.RADJPRON.iloc[i]=adj/pronoun\n",
        "    brownpostable.RADVADJ.iloc[i]=adv/adj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1e_azMB7Xqm6"
      },
      "outputs": [],
      "source": [
        "brownpostable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fl5Gv3dlXqm6"
      },
      "outputs": [],
      "source": [
        "# Re-categorise the Brown corpus categories as fiction and non-fiction.\n",
        "# 5 categories are identified as fiction, 5 as non-fiction and the remaining 5 are dropped due to ambiguity.\n",
        "\n",
        "brown2=brownpostable.copy()\n",
        "for i in ['news','reviews','government','learned','hobbies']:\n",
        "    brown2=brown2.replace(to_replace=i,value='nonfiction')\n",
        "\n",
        "for i in ['fiction','mystery','science_fiction','adventure','romance']:\n",
        "    brown2=brown2.replace(to_replace=i,value='fiction')\n",
        "    \n",
        "index_names=brown2[(brown2['category'] != 'fiction') & (brown2['category'] != 'nonfiction')].index\n",
        "brown2.drop(index_names,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "brown2.drop(columns=['filename','PRON','ADJ','ADV','NOUN','VERB'],inplace=True)"
      ],
      "metadata": {
        "id": "OI1ePX9C1OSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brown2"
      ],
      "metadata": {
        "id": "7ESDBvXI1U86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(data=brown2, hue='category', x='RADVADJ', y='RADJPRON')"
      ],
      "metadata": {
        "id": "BkUcWUPV1juX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlJIiE68Xqm7"
      },
      "outputs": [],
      "source": [
        "# replace the text labels by numbers\n",
        "brown3=brown2.replace(to_replace='nonfiction',value='0')\n",
        "brown3=brown3.replace(to_replace='fiction',value='1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoCqZquPXqm7"
      },
      "outputs": [],
      "source": [
        "brown3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-boFZ9upXqm8"
      },
      "outputs": [],
      "source": [
        "x=brown3.drop(columns=['category'])\n",
        "y=brown3.category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ47qa8xXqm8"
      },
      "outputs": [],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKgWQWOWXqm8"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_Q3e3qAXqm8"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "logreg = LogisticRegression(solver='lbfgs')\n",
        "logreg.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9n6zh-RXqm8"
      },
      "outputs": [],
      "source": [
        "# Training accuracy\n",
        "\n",
        "y_pred=logreg.predict(x_train)\n",
        "accuracy = metrics.accuracy_score(y_train,y_pred)\n",
        "print(\"Training Accuracy : \",accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POyF3prUXqm9"
      },
      "outputs": [],
      "source": [
        "# Testing accuracy\n",
        "\n",
        "y_pred=logreg.predict(x_test)\n",
        "accuracy = metrics.accuracy_score(y_test,y_pred)\n",
        "print(\"Testing Accuracy : \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhQHeonVXqm9"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test,y_pred)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['nonfiction', 'fiction'])\n",
        "disp.plot(cmap=plt.cm.Blues)  # plot the confusion matrix\n",
        "plt.show()  # show the plot"
      ],
      "metadata": {
        "id": "TRbMNr_BYMbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter values of Logistic Regression after training\n",
        "print(logreg.intercept_)\n",
        "print(logreg.coef_)"
      ],
      "metadata": {
        "id": "bQBE0NTlYjoc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}